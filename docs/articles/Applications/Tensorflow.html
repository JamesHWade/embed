<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Entity Embeddings of Categorical Variables using Tensorflow • embed</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/united/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<meta property="og:title" content="Entity Embeddings of Categorical Variables using Tensorflow">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">embed</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.0.0.9001</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../articles/Applications/GLM.html">Generalized Linear Models</a>
</li>
<li>
  <a href="../../articles/Applications/Tensorflow.html">Tensorflow</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Entity Embeddings of Categorical Variables using Tensorflow</h1>
            
      
      
      <div class="hidden name"><code>Tensorflow.Rmd</code></div>

    </div>

    
    
<p>The approach encodes categorical data as multiple numeric variables using a <em>word embedding</em> approach. Originally intended as a way to take a large number of word identifiers and represent them in a smaller dimension. Good references on this are <a href="https://arxiv.org/abs/1604.06737">Guo and Berkhahn (2016)</a> and Chapter 6 of <a href="https://www.manning.com/books/deep-learning-with-r">Francois and Allaire (2018)</a>.</p>
<p>The methodology first translates the <em>C</em> factor levels as a set of integer values then randomly allocates them to the new <em>D</em> numeric columns. These columns are optionally connected in a neural network to an intermediate layer of hidden units. This implementation uses a single layer with ReLu activations. Finally, an output layer is used with either linear activation (for numeric outcomes) or softmax (for classification).</p>
<p>To translate this model to a set of embeddings, the coefficients of the original embedding layer are used to represent the original factor levels.</p>
<p>As an example, we use the Ames housing data where the sale price of houses are being predicted. One predictor, neighborhood, has the most factor levels of the predictors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(AmesHousing)
ames &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/AmesHousing/topics/make_ames">make_ames</a></span>()
<span class="kw">length</span>(<span class="kw">levels</span>(ames<span class="op">$</span>Neighborhood))</code></pre></div>
<pre><code>## [1] 28</code></pre>
<p>The distribution of data in the neighborhood is not uniform:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(ames, <span class="kw">aes</span>(<span class="dt">x =</span> Neighborhood)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">""</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="Tensorflow_files/figure-html/ames-xtab-1.png" width="700"></p>
<p>Fo plotting later, we calculate the simple means per neighborhood:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">means &lt;-<span class="st"> </span>ames <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(Neighborhood) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(
    <span class="dt">mean =</span> <span class="kw">mean</span>(<span class="kw">log10</span>(Sale_Price)),
    <span class="dt">n =</span> <span class="kw">length</span>(Sale_Price),
    <span class="dt">lon =</span> <span class="kw">median</span>(Longitude),
    <span class="dt">lat =</span> <span class="kw">median</span>(Latitude)
  )</code></pre></div>
<p>First, we’ll fit a model with no hidden units and 10 encoding columns:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(embed)
tf_linear &lt;-<span class="st"> </span><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>MS_SubClass, <span class="dt">data =</span> ames) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">step_log</span>(Sale_Price, <span class="dt">base =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../../reference/step_embed.html">step_embed</a></span>(
    Neighborhood, <span class="dt">outcome =</span> <span class="kw">vars</span>(Sale_Price),
    <span class="dt">number =</span> <span class="dv">10</span>, 
    <span class="dt">options =</span> <span class="kw"><a href="../../reference/step_embed.html">embed_control</a></span>(<span class="dt">epochs =</span> <span class="dv">50</span>)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">prep</span>(<span class="dt">training =</span> ames)</code></pre></div>
<p>The embeddings are obtained using the <code>tidy</code> method:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">linear_coef &lt;-<span class="st"> </span><span class="kw">tidy</span>(tf_linear, <span class="dt">number =</span> <span class="dv">2</span>)
linear_coef</code></pre></div>
<pre><code>## # A tibble: 29 x 12
##       emb01   emb02    emb03   emb04   emb05   emb06    emb07  emb08
##       &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;
##  1 -0.0213  -0.0373  0.0195   0.0483 -0.0312  0.0107 -0.00834 0.0314
##  2 -0.0418   0.122  -0.0342  -0.129   0.133  -0.0679 -0.0964  0.114 
##  3 -0.0510   0.156   0.0149  -0.145   0.151  -0.111  -0.0488  0.102 
##  4 -0.0478   0.0659 -0.00411 -0.0846  0.135  -0.133  -0.0460  0.0917
##  5  0.00159  0.115  -0.0356  -0.108   0.0747 -0.129  -0.0950  0.0557
##  6 -0.112    0.165  -0.0325  -0.163   0.167  -0.116  -0.0556  0.0714
##  7 -0.0449   0.190   0.00222 -0.178   0.148  -0.206  -0.111   0.114 
##  8 -0.0920   0.156  -0.00894 -0.156   0.108  -0.130  -0.0940  0.130 
##  9 -0.00714  0.144  -0.0344  -0.0756  0.0823 -0.159  -0.0179  0.0919
## 10 -0.0491   0.156  -0.00358 -0.108   0.106  -0.166  -0.0305  0.107 
## # ... with 19 more rows, and 4 more variables: emb09 &lt;dbl&gt;, emb10 &lt;dbl&gt;,
## #   level &lt;chr&gt;, terms &lt;chr&gt;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">linear_coef &lt;-<span class="st"> </span>linear_coef <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">rename</a></span>(<span class="dt">Neighborhood =</span> level) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">inner_join</span>(means, <span class="dt">by =</span> <span class="st">"Neighborhood"</span>)</code></pre></div>
<p>There is some columns that are correlated with the outcome:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">linear_cor &lt;-<span class="st"> </span>linear_coef <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="kw">starts_with</span>(<span class="st">"emb"</span>), mean) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cor</span>()
linear_cor[<span class="op">-</span><span class="dv">11</span>,<span class="dv">11</span>]</code></pre></div>
<pre><code>## emb01 emb02 emb03 emb04 emb05 emb06 emb07 emb08 emb09 emb10 
## -0.23  0.52 -0.20 -0.65  0.45 -0.57 -0.16  0.39 -0.12  0.41</code></pre>
<p>However, this has induced some between-predictor correlations.</p>
<p><a href="https://en.wikipedia.org/wiki/Multidimensional_scaling">Multidimensional scaling</a> is used to see if there is any information in the data that is associated with the outcome:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lin_mds &lt;-<span class="st"> </span>linear_coef <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="kw">starts_with</span>(<span class="st">"emb"</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">dist</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sammon</span>(<span class="dt">trace =</span> <span class="ot">FALSE</span>)
lin_mds<span class="op">$</span>points <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(linear_coef <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(Neighborhood, mean)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(comp, mds_value, <span class="op">-</span>Neighborhood, <span class="op">-</span>mean) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mds_value, <span class="dt">y =</span> mean)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>comp) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="Tensorflow_files/figure-html/linear-mds-1.png" width="700"></p>
<p>Note that, since these methods are <strong>supervised</strong>, using the new encodings in a model where <em>the same data are being used</em>, the estimate of model performance may yield overly optimistic results.</p>
<p>Now let’s fit a more complex model with a layer of hidden units.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tf_nlin &lt;-<span class="st"> </span><span class="kw">recipe</span>(Sale_Price <span class="op">~</span><span class="st"> </span>Neighborhood <span class="op">+</span><span class="st"> </span>MS_SubClass, <span class="dt">data =</span> ames) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">step_log</span>(Sale_Price, <span class="dt">base =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../../reference/step_embed.html">step_embed</a></span>(
    Neighborhood, <span class="dt">outcome =</span> <span class="kw">vars</span>(Sale_Price),
    <span class="dt">number =</span> <span class="dv">10</span>, 
    <span class="dt">hidden =</span> <span class="dv">50</span>,
    <span class="dt">options =</span> <span class="kw"><a href="../../reference/step_embed.html">embed_control</a></span>(<span class="dt">epochs =</span> <span class="dv">50</span>)
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">prep</span>(<span class="dt">training =</span> ames)

nlin_coef &lt;-<span class="st"> </span><span class="kw">tidy</span>(tf_nlin, <span class="dt">number =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">rename</a></span>(<span class="dt">Neighborhood =</span> level) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">inner_join</span>(means, <span class="dt">by =</span> <span class="st">"Neighborhood"</span>)</code></pre></div>
<pre><code>## Warning: Column `Neighborhood` joining character vector and factor,
## coercing into character vector</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nlin_cor &lt;-<span class="st"> </span>nlin_coef <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="kw">starts_with</span>(<span class="st">"emb"</span>), mean) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cor</span>()
nlin_cor[<span class="op">-</span><span class="dv">11</span>,<span class="dv">11</span>]</code></pre></div>
<pre><code>## emb01 emb02 emb03 emb04 emb05 emb06 emb07 emb08 emb09 emb10 
## -0.21  0.87 -0.80  0.53 -0.20 -0.66  0.71  0.28 -0.56  0.52</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nlin_mds &lt;-<span class="st"> </span>nlin_coef <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># dplyr::filter(Neighborhood != "..new") %&gt;% </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="kw">starts_with</span>(<span class="st">"emb"</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">dist</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sammon</span>(<span class="dt">trace =</span> <span class="ot">FALSE</span>)
nlin_mds<span class="op">$</span>points <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(nlin_coef <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(Neighborhood, mean)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(comp, mds_value, <span class="op">-</span>Neighborhood, <span class="op">-</span>mean) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mds_value, <span class="dt">y =</span> mean)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>comp) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="Tensorflow_files/figure-html/ames-nonlinear-1.png" width="700"></p>
<p>Arguably, there appears to be a slightly better association with the sample means using the extra layer.</p>
<p>The new levels are encoded as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(tf_nlin, <span class="dt">number =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/filter.html">filter</a></span>(level <span class="op">==</span><span class="st"> "..new"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(<span class="kw">starts_with</span>(<span class="st">"emb"</span>))</code></pre></div>
<pre><code>## # A tibble: 1 x 10
##    emb01   emb02   emb03  emb04   emb05   emb06  emb07   emb08  emb09
##    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1 0.0317 -0.0133 -0.0461 0.0140 -0.0201 0.00895 0.0155 -0.0310 0.0446
## # ... with 1 more variable: emb10 &lt;dbl&gt;</code></pre>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Max Kuhn.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
